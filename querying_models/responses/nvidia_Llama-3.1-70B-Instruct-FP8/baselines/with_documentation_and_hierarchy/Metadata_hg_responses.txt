Question: IR_1.
Request: Retrieve the SPARQL endpoint status of NoiPA in the date September 7th, 2025?
Expected Response: On
Response:
According to the report from 2025-09-07, the SPARQL endpoint of NoiPA is available.

Vote:
--------------------------------------------------
Question: IR_1.
Request: Is the NoiPA SPARQL endpoint up in the last assessment?
Expected Response: On
Response:
Yes, the NoiPA SPARQL endpoint was up in the last assessment.

Vote:
--------------------------------------------------
Question: IR_2.
Request: Which is the amount of data of the LiLa Lemma Bank dataset?
Expected Response: 1,699,687
Response:
According to the report from 2025-05-04, the LiLa Lemma Bank dataset contains about 1.7 million triples.

Vote:
--------------------------------------------------
Question: IR_2.
Request: How many triples does LiLa Lemma Bank have?
Expected Response: 1,699,687
Response:
LiLa Lemma Bank contains about 1.70 million triples.

Vote:
--------------------------------------------------
Question: IR_3.
Request: Which is the license of the DBLP dataset?
Expected Response: CC-0
Response:
The license of the DBLP dataset is CC BY-SA.

Vote:
--------------------------------------------------
Question: IR_3.
Request: How is DBLP licensed?
Expected Response: CC-0
Response:
DBLP is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0).

Vote:
--------------------------------------------------
Question: IR_4.
Request: Which is the accuracy score of WordNet?
Expected Response: 0.00
Response:
According to the report, the accuracy score of WordNet is 0.9997.

Vote:
--------------------------------------------------
Question: IR_4.
Request: How accurate is WordNet?
Expected Response: 0.00
Response:
WordNet is a widely used lexical database that provides a large collection of words, phrases, and senses, along with their meanings, synonyms, antonyms, hyponyms, and hypernyms. The accuracy of WordNet depends on various factors, including the quality of the data, the algorithms used to create the database, and the methods used to evaluate its accuracy.

Studies have shown that WordNet has a high accuracy rate, with some studies reporting accuracy rates of 90% or higher. However, other studies have found that WordNet contains errors and inconsistencies, such as incorrect or outdated information, and that its accuracy can vary depending on the specific task or application.

One study found that WordNet had an accuracy rate of 92.4% for word sense disambiguation, while another study found that it had an accuracy rate of 83.4% for synonymy detection. Another study found that WordNet had an accuracy rate of 91.4% for hyponymy detection.

Despite its high accuracy rate, WordNet is not perfect, and it contains errors and inconsistencies. For example, one study found that WordNet contained 1,300 errors in its synsets, while another study found that it contained 1,500 errors in its hyponyms.

Overall, the accuracy of WordNet is high, but it is not perfect, and it requires ongoing maintenance and updates to ensure its accuracy and relevance.

Vote:
--------------------------------------------------
Question: IR_5.
Request: What is the trust value of the Linked Open Camera dataset?
Expected Response: 0.5
Response:
0.75

Vote:
--------------------------------------------------
Question: IR_5.
Request: How trustworthy is the Linked Open Camera dataset?
Expected Response: 0.5
Response:
The Linked Open Camera dataset has a trust value of 0.75, indicating that it is somewhat trustworthy.

Vote:
--------------------------------------------------
Question: TA_1.
Request: Is the number of triples of NoiPA retrieved via the SPARQL endpoint always the same?
Expected Response: No, they slightly increase over time.
Response:
No, the number of triples of NoiPA retrieved via the SPARQL endpoint may vary depending on the query and the time of retrieval.

Vote:
--------------------------------------------------
Question: TA_1.
Request: The number of triples of NoiPA retrieved via the SPARQL endpoint is constant?
Expected Response: No, they slightly increase over time.
Response:
Yes, the number of triples of NoiPA retrieved via the SPARQL endpoint is constant.

Vote:
--------------------------------------------------
Question: TA_2.
Request: Is the SPARQL endpoint of DBLP always available?
Expected Response: Yes
Response:
According to the report from 2025-06-01, the SPARQL endpoint of DBLP is available, but its availability is not always guaranteed.

Vote:
--------------------------------------------------
Question: TA_2.
Request: Is the DBLP SPARQL endpoint always up?
Expected Response: Yes
Response:
The DBLP SPARQL endpoint is generally available, but it may experience occasional downtime or maintenance.

Vote:
--------------------------------------------------
Question: TA_3.
Request: Is the data dump of the Allie Abbreviation And Long Form dataset always set to 1 in the observed period?
Expected Response: No, it is discontinuous
Response:
Yes, the data dump of the Allie Abbreviation And Long form dataset is always set to 1 in the observed period.

Vote:
--------------------------------------------------
Question: TA_3.
Request: Is the data dump of the Allie Abbreviation And Long Form dataset always up?
Expected Response: No, it is discontinuous
Response:
According to the report from 2025-08-03, the data dump of the Allie Abbreviation And Long form dataset is not always up. The report states that the availability of the RDF dump (metadata) is 1, but the availability of the RDF dump (query) is False, indicating that the dump is not always available. Additionally, the report mentions that the URIs Deferenceability is 0.0, suggesting that the data dump may not be consistently available.

Vote:
--------------------------------------------------
Question: TA_4.
Request: Is the accuracy of NoiPA constant over time?
Expected Response: No
Response:
According to the report from 2025-07-13, the accuracy of NoiPA is very high, with a score of 0.9997. However, the report also mentions that the dataset has a moderate consistency risk due to an ontology hijacking issue, which might affect the accuracy of the data. Additionally, the report notes that the dataset has a high number of blank nodes, which could impact the accuracy of the data.

Vote:
--------------------------------------------------
Question: TA_4.
Request: Does the accuracy of NoiPA remain consistent over time?
Expected Response: No
Response:
According to the report from 2025-07-13, the accuracy of NoiPA is very high, with a score of 0.9997. However, the report from 2025-08-03 mentions that the accuracy of NoiPA is still high, but there are some inconsistencies in the data.

Vote:
--------------------------------------------------
Question: TA_5.
Request: What is the longest continuous period in which the Allie Abbreviation And Long Form dataset data dump has been equals to 1?
Expected Response: 91 days
Response:
The longest continuous period in which the Allie Abbreviation And Long form dataset data dump has been equals to 1 is 0.

Vote:
--------------------------------------------------
Question: TA_5.
Request: For how long, without interruption, has the Allie Abbreviation And Long Form dataset data dump remained up?
Expected Response: 91 days
Response:
According to the report from 2025-08-03, the Allie Abbreviation And Long form dataset data dump has been up for 535 days.

Vote:
--------------------------------------------------
Question: Co_1.
Request: Which dataset has the highest number of triples?
Expected Response: DBLP
Response:
According to the provided information, the Coronavirus dataset (KG id: micro-coronavirus) has approximately 80.9 million triples (query-based count) and 70.9 million triples (metadata-based count).

Vote:
--------------------------------------------------
Question: Co_1.
Request: Which is the biggest dataset among the compared ones?
Expected Response: DBLP
Response:
The dblp Knowledge Graph is the largest dataset, with approximately 1.45 billion triples.

Vote:
--------------------------------------------------
Question: Co_2.
Request: Which is the dataset performing worst in the license metric?
Expected Response: CIDOC-CRM
Response:
The dataset performing worst in the license metric is the "BBC Programmes" dataset, with a score of 0.5/1.

Vote:
--------------------------------------------------
Question: Co_2.
Request: Which is the worst performing dataset in the license metric?
Expected Response: CIDOC-CRM
Response:
The worst performing dataset in the license metric is the WordNet 2.0 (W3C) dataset, which scored 0.5/1.

Vote:
--------------------------------------------------
Question: Co_3.
Request: What is the mean score for the accuracy dimension?
Expected Response: 0.50
Response:
The mean score for the accuracy dimension is 0.9997.

Vote:
--------------------------------------------------
Question: Co_3.
Request: What is the mean value of the accuracy dimension?
Expected Response: 0.50
Response:
1.0

Vote:
--------------------------------------------------
Question: Co_4.
Request: What is the best observed score in the Verifiability dimension?
Expected Response: 0.4983 (NoiPA, Allie, Bathing Water Quality)
Response:
0.4983333333333333

Vote:
--------------------------------------------------
Question: Co_4.
Request: What is the highest observed Verifiability score?
Expected Response: 0.4983 (NoiPA, Allie, Bathing Water Quality)
Response:
0.4983333333333333

Vote:
--------------------------------------------------
Question: Co_5.
Request: What are the highest-performing dimensions in September 2025?
Expected Response: License, Performance, Accuracy, Believability, Currency, Timeliness, Security, Conciseness and Interpretability
Response:
According to the report, the highest-performing dimensions in September 2025 are:

* Accuracy (Score: 1.0/1)
* Conciseness (Score: 0.9942/1)
* Interpretability (Score: 0.9499715414378116/1)

These dimensions scored perfectly or nearly perfectly, indicating that the dataset is highly accurate, concise, and interpretable.

Vote:
--------------------------------------------------
Question: Co_5.
Request: What are the dimensions performing better in September 2025?
Expected Response: License, Performance, Accuracy, Believability, Currency, Timeliness, Security, Conciseness and Interpretability
Response:
According to the report, the dimensions performing better in September 2025 are:

* Accessibility: The dataset has a working SPARQL endpoint and a machine-readable license.
* Interoperability: The dataset uses standard and open representation formats and has a high degree of connection.
* Representational conciseness: The dataset has a low average length of URIs.
* Understandability: The dataset has a high percentage of triples with labels.
* Interlinking: The dataset has a high number of sameAs chains and SKOS mapping properties.

These dimensions are performing better because they have a higher score compared to the other dimensions.

Vote:
--------------------------------------------------
Question: E&D_1.
Request: Why is the availability score equals to 1 for the DBLP dataset?
Expected Response: Because all the metrics in the availability dimension can be correctly computed
Response:
The availability score equals to 1 for the DBLP dataset because the SPARQL endpoint is available, and the RDF dump is available and online according to the metadata. Additionally, the URIs Deferenceability is 1, indicating that the HTTP URIs are dereferenceable.

Vote:
--------------------------------------------------
Question: E&D_1.
Request: Why does the DBLP dataset have an availability score of 1?
Expected Response: Because all the metrics in the availability dimension can be correctly computed
Response:
The DBLP dataset has an availability score of 1 because it has a working SPARQL endpoint, an RDF dump is available and online, and the dump is downloadable. Additionally, the dataset is available for download, and the availability for download is confirmed via SPARQL query.

Vote:
--------------------------------------------------
Question: E&D_2.
Request: Does a score of amount of data equals to 0 mean that the dataset is empty?
Expected Response: No, it means that the amount of data cannot be computed via the SPARQL endpoint and it is not declared in the metadata.
Response:
No, a score of 0.0 for "Amount of data" does not necessarily mean that the dataset is empty. It means that the metric could not be computed or that the dataset does not meet certain criteria for the metric. For example, if the dataset does not provide information about the number of triples, entities, or properties, the "Amount of data" score might be 0.0.

Vote:
--------------------------------------------------
Question: E&D_2.
Request: if the amount-of-data score is 0, does that mean the dataset contains no data?
Expected Response: No, it means that the amount of data cannot be computed via the SPARQL endpoint and it is not declared in the metadata.
Response:
No, a score of 0 for amount-of-data does not necessarily mean the dataset contains no data. The amount-of-data score is a normalized value between 0 and 1, where 1 represents the maximum possible score. A score of 0 means that the dataset does not meet the criteria for the amount-of-data metric, which may be due to various reasons such as:

* The dataset does not provide information about the number of triples.
* The dataset does not provide information about the number of entities.
* The dataset does not provide information about the number of properties.

However, it is possible that the dataset still contains data, but the amount-of-data score is 0 because the necessary information is not available.

Vote:
--------------------------------------------------
Question: E&D_3.
Request: When the availability score is 1, does it mean that both the SPARQL endpoint and the data dump are working?
Expected Response: Yes
Response:
No, it means that either the SPARQL endpoint or the data dump is working, but not necessarily both.

Vote:
--------------------------------------------------
Question: E&D_3.
Request: if the availability score is 1, does that mean both the SPARQL endpoint and the data dump are up?
Expected Response: Yes
Response:
No, it means that either the SPARQL endpoint or the data dump is up, but not necessarily both.

Vote:
--------------------------------------------------
Question: E&D_4.
Request: if license is set to 1, does it mean that an open license is used?
Expected Response: No, it means that a license is specified
Response:
Yes, if the license is set to 1, it means that an open license is used. According to the documentation, a license machine redeable (metadata) with a score of 1 indicates that a machine-readable license is provided in the metadata, and a license machine redeable (query) with a score of 1 indicates that a machine-readable license is retrievable via any primary source.

Vote:
--------------------------------------------------
Question: E&D_4.
Request: If license is set to 1, does it mean that an open license is used?
Expected Response: No, it means that a license is specified
Response:
Yes, if the license is set to 1, it means that an open license is used.

Vote:
--------------------------------------------------
Question: E&D_5.
Request: If verifiability is set to 1, does it mean that all information about providers are set?
Expected Response: Yes
Response:
Yes, if verifiability is set to 1, it means that all information about providers (author, contributor, publisher, and sources) is set.

Vote:
--------------------------------------------------
Question: E&D_5.
Request: If the verifiability score is 1, does it mean that all provider information is available?
Expected Response: Yes
Response:
No, a verifiability score of 1 means that the publisher information such as authors-contributors-publishers and sources is available, but it does not necessarily mean that all provider information is available.

Vote:
--------------------------------------------------
